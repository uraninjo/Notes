{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 - Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    \"NB\": GaussianNB(),\n",
    "    \"SGD\": SGDClassifier(),\n",
    "    \"KNN\": KNeighborsClassifier(), \n",
    "    \"LR\": LogisticRegression(max_iter=1000), \n",
    "    \"DT\": DecisionTreeClassifier(),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=100, max_depth=3, random_state=2),\n",
    "    \"SVM\": SVC(),\n",
    "    \"MLP\": MLPClassifier(max_iter=1000),\n",
    "    \"XGB\": XGBClassifier(),\n",
    "    \"LGBM\": LGBMClassifier()\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Classifier\", \"Avg_Accuracy\", \"Avg_F1_Score\"])\n",
    "for name, clf in classifiers.items():\n",
    "    model = clf\n",
    "    cv_results = cross_validate(\n",
    "        model, X_train_scaled, y_train, cv=10,\n",
    "        scoring=(['accuracy', 'f1'])\n",
    "    )\n",
    "\n",
    "    results = results.append({\n",
    "        \"Classifier\": name,\n",
    "        \"Avg_Accuracy\": cv_results['test_accuracy'].mean(),\n",
    "        \"Avg_F1_Score\": cv_results['test_f1'].mean()\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "results[\"Avg_Overall\"] = (results[\"Avg_Accuracy\"] + results[\"Avg_F1_Score\"]) / 2\n",
    "results = results.sort_values(\"Avg_Overall\", ascending=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = {\n",
    "    \"SGD\": SGDRegressor(),\n",
    "    \"KNN\": KNeighborsRegressor(), \n",
    "    \"LR\": LogisticRegression(max_iter=1000), \n",
    "    \"DT\": DecisionTreeRegressor(),\n",
    "    \"RF\": RandomForestRegressor(max_depth=3, random_state=2),\n",
    "    \"SVM\": SVC(),\n",
    "    \"MLP\": MLPRegressor(max_iter=1000),\n",
    "    \"XGB\": XGBRegressor(),\n",
    "    \"LGBM\": LGBMRegressor()\n",
    "}\n",
    "\n",
    "results = pd.DataFrame(columns=[\"Regressor\", \"rmse\", \"r2\"])\n",
    "for name, clf in regressor.items():\n",
    "    model = clf\n",
    "    clf.fit(X_train_scaled,y_train)\n",
    "    predictions = clf.predict(X_pred)\n",
    "    results = results.append({\n",
    "        \"Regressor\": name,\n",
    "        \"rmse\": np.sqrt(np.square(y_test - predictions)).mean(),\n",
    "        \"r2\": 1 - np.square(y_test - predictions).sum()/np.square(y_test - y_test.mean()).sum(),\n",
    "    }, ignore_index=True)\n",
    "    \n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))\n",
    "\n",
    "def cv_rmse(model):\n",
    "    rmse = np.sqrt(-cross_val_score(model, train, target_log, scoring=\"neg_mean_squared_error\", cv=kf))\n",
    "    return (rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "cv_scores = []\n",
    "cv_std = []\n",
    "\n",
    "baseline_models = ['Linear_Reg.','Bayesian_Ridge_Reg.','LGBM_Reg.','SVR',\n",
    "                   'Dec_Tree_Reg.','Random_Forest_Reg.', 'XGB_Reg.',\n",
    "                   'Grad_Boost_Reg.','Cat_Boost_Reg.','Stacked_Reg.']\n",
    "\n",
    "# Linear Regression\n",
    "\n",
    "lreg = LinearRegression()\n",
    "score_lreg = cv_rmse(lreg)\n",
    "cv_scores.append(score_lreg.mean())\n",
    "cv_std.append(score_lreg.std())\n",
    "\n",
    "# Bayesian Ridge Regression\n",
    "\n",
    "brr = BayesianRidge(compute_score=True)\n",
    "score_brr = cv_rmse(brr)\n",
    "cv_scores.append(score_brr.mean())\n",
    "cv_std.append(score_brr.std())\n",
    "\n",
    "# Light Gradient Boost Regressor\n",
    "\n",
    "l_gbm = LGBMRegressor(objective='regression')\n",
    "score_l_gbm = cv_rmse(l_gbm)\n",
    "cv_scores.append(score_l_gbm.mean())\n",
    "cv_std.append(score_l_gbm.std())\n",
    "\n",
    "# Support Vector Regression\n",
    "\n",
    "svr = SVR()\n",
    "score_svr = cv_rmse(svr)\n",
    "cv_scores.append(score_svr.mean())\n",
    "cv_std.append(score_svr.std())\n",
    "\n",
    "# Decision Tree Regressor\n",
    "\n",
    "dtr = DecisionTreeRegressor()\n",
    "score_dtr = cv_rmse(dtr)\n",
    "cv_scores.append(score_dtr.mean())\n",
    "cv_std.append(score_dtr.std())\n",
    "\n",
    "# Random Forest Regressor\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "score_rfr = cv_rmse(rfr)\n",
    "cv_scores.append(score_rfr.mean())\n",
    "cv_std.append(score_rfr.std())\n",
    "\n",
    "# XGB Regressor\n",
    "\n",
    "xgb = xgb.XGBRegressor()\n",
    "score_xgb = cv_rmse(xgb)\n",
    "cv_scores.append(score_xgb.mean())\n",
    "cv_std.append(score_xgb.std())\n",
    "\n",
    "# Gradient Boost Regressor\n",
    "\n",
    "gbr = GradientBoostingRegressor()\n",
    "score_gbr = cv_rmse(gbr)\n",
    "cv_scores.append(score_gbr.mean())\n",
    "cv_std.append(score_gbr.std())\n",
    "\n",
    "# Cat Boost Regressor\n",
    "\n",
    "catb = CatBoostRegressor()\n",
    "score_catb = cv_rmse(catb)\n",
    "cv_scores.append(score_catb.mean())\n",
    "cv_std.append(score_catb.std())\n",
    "\n",
    "# Stacked Regressor\n",
    "\n",
    "stack_gen = StackingRegressor(regressors=(CatBoostRegressor(),\n",
    "                                          LinearRegression(),\n",
    "                                          BayesianRidge(),\n",
    "                                          GradientBoostingRegressor()),\n",
    "                              meta_regressor = CatBoostRegressor(),\n",
    "                              use_features_in_secondary = True)\n",
    "\n",
    "score_stack_gen = cv_rmse(stack_gen)\n",
    "cv_scores.append(score_stack_gen.mean())\n",
    "cv_std.append(score_stack_gen.std())\n",
    "\n",
    "final_cv_score = pd.DataFrame(baseline_models, columns = ['Regressors'])\n",
    "final_cv_score['RMSE_mean'] = cv_scores\n",
    "final_cv_score['RMSE_std'] = cv_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cda057ccb0cb91c9ce59470e73901b3641e671a10f07be5ab4825eb80c5cbae8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
